{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORTS\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import random\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, Activation, MaxPooling2D, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative labels:  11277\n",
      "Positive labels:  15864\n"
     ]
    }
   ],
   "source": [
    "pos = os.listdir('Data/Training/BrickImages')\n",
    "neg =  os.listdir('Data/Training/NoBrickImages')\n",
    "neg = ['Data/Training/NoBrickImages/'+ i for i in neg]\n",
    "pos = ['Data/Training/BrickImages/'+ i for i in pos]\n",
    "print(\"Negative labels: \",len(neg))\n",
    "print(\"Positive labels: \",len(pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale = 1.0/255, \n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    shear_range= 10,\n",
    "    vertical_flip= True\n",
    ")\n",
    "\n",
    "test_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale = 1.0/255, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 27140 images belonging to 2 classes.\n",
      "Found 3280 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds = train_gen.flow_from_directory(\n",
    "        'Data/Training',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary'\n",
    ")\n",
    "\n",
    "test_ds = test_gen.flow_from_directory(\n",
    "        'Data/Validation',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 3)\n",
      "Creating Model\n"
     ]
    }
   ],
   "source": [
    "### CREATE SEQUENTIAL MODEL\n",
    "\n",
    "input_shape = (64, 64, 3)\n",
    "print (input_shape)\n",
    "print('Creating Model')\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#filters,kernel_size,strides=(1, 1),padding='valid',data_format=None,dilation_rate=(1, 1),activation=None,use_bias=True,\n",
    "#kernel_initializer='glorot_uniform',bias_initializer='zeros',kernel_regularizer=None,bias_regularizer=None,\n",
    "#activity_regularizer=None,kernel_constraint=None,bias_constraint=None,\n",
    "\n",
    "#pool_size=(2, 2), strides=None, padding='valid',data_format=None\n",
    "\n",
    "model.add(Conv2D(32, (3,3),padding='same',input_shape=input_shape,name='conv2d_1'))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2),name='maxpool2d_1'))\n",
    "\n",
    "model.add(Conv2D(64, 3, 3, name='conv2d_6'))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(32))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(1)) #config.num_classes\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COMPILE MODEL\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='Adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "849/849 [==============================] - 374s 441ms/step - loss: 0.0986 - accuracy: 0.9696 - val_loss: 0.0580 - val_accuracy: 0.9802\n",
      "Epoch 2/10\n",
      "849/849 [==============================] - 50s 59ms/step - loss: 0.0845 - accuracy: 0.9745 - val_loss: 0.0555 - val_accuracy: 0.9838\n",
      "Epoch 3/10\n",
      "849/849 [==============================] - 64s 75ms/step - loss: 0.0823 - accuracy: 0.9742 - val_loss: 0.0622 - val_accuracy: 0.9820\n",
      "Epoch 4/10\n",
      "849/849 [==============================] - 66s 78ms/step - loss: 0.0852 - accuracy: 0.9746 - val_loss: 0.0773 - val_accuracy: 0.9845\n",
      "Epoch 5/10\n",
      "849/849 [==============================] - 69s 81ms/step - loss: 0.0780 - accuracy: 0.9748 - val_loss: 0.0651 - val_accuracy: 0.9765\n",
      "Epoch 6/10\n",
      "849/849 [==============================] - 66s 78ms/step - loss: 0.0770 - accuracy: 0.9759 - val_loss: 0.0668 - val_accuracy: 0.9790\n",
      "Epoch 7/10\n",
      "849/849 [==============================] - 64s 75ms/step - loss: 0.0773 - accuracy: 0.9757 - val_loss: 0.0725 - val_accuracy: 0.9668\n",
      "Epoch 8/10\n",
      "849/849 [==============================] - 59s 70ms/step - loss: 0.0743 - accuracy: 0.9761 - val_loss: 0.0517 - val_accuracy: 0.9863\n",
      "Epoch 9/10\n",
      "849/849 [==============================] - 48s 57ms/step - loss: 0.0754 - accuracy: 0.9765 - val_loss: 0.0664 - val_accuracy: 0.9854\n",
      "Epoch 10/10\n",
      "849/849 [==============================] - 54s 63ms/step - loss: 0.0733 - accuracy: 0.9770 - val_loss: 0.0829 - val_accuracy: 0.9634\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb9d009b790>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TRAIN MODEL\n",
    "\n",
    "model.fit(\n",
    "        train_ds,\n",
    "        epochs=5, #config.num_epochs\n",
    "        validation_data=test_ds, \n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"Models/smally_rack_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"Models/smally_rack_model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-venv",
   "language": "python",
   "name": "local-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
